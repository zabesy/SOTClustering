{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "ThesisClustering.ipynb",
   "provenance": [],
   "collapsed_sections": [],
   "mount_file_id": "1Y_Pi1BIYybISVb00nrSP3J2ZVOMl24bU",
   "authorship_tag": "ABX9TyPqtR0V7cu/9c8zZfHqStSr"
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "id": "WikwhI2T2ozI",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1633372462460,
     "user_tz": -120,
     "elapsed": 131923,
     "user": {
      "displayName": "adam-nord@hotmail.com",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "12454353131717006596"
     }
    }
   },
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import time\n",
    "import math\n",
    "from matplotlib.offsetbox import AnnotationBbox, OffsetImage\n",
    "import ipywidgets as widgets\n",
    "import plotly.graph_objects as go\n",
    "from ipywidgets import Layout\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "from nltk.cluster import KMeansClusterer\n",
    "import nltk  \n",
    "from sklearn import cluster\n",
    "from sklearn import metrics\n",
    "import gensim.downloader as api"
   ],
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Load googles w2v model."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "w2v = api.load('word2vec-google-news-300')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Save the model."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "#import tempfile\n",
    "\n",
    "#with tempfile.NamedTemporaryFile(prefix='gensim-model-', delete=False) as tmp:\n",
    "#    temporary_filepath = tmp.name\n",
    "#    w2v.save(temporary_filepath)\n",
    "    #\n",
    "    # The model is now safely stored in the filepath.\n",
    "    # You can copy it to other machines, share it with others, etc.\n",
    "    #\n",
    "    # To load a saved model:\n",
    "    #\n",
    "#    new_model = Word2Vec.load(temporary_filepath)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "                    title author school  \\\n0  Plato - Complete Works  Plato  plato   \n1  Plato - Complete Works  Plato  plato   \n2  Plato - Complete Works  Plato  plato   \n3  Plato - Complete Works  Plato  plato   \n4  Plato - Complete Works  Plato  plato   \n\n                                      sentence_spacy  \\\n0   What's new, Socrates, to make you leave your ...   \n1  Surely you are not prosecuting anyone before t...   \n2  The Athenians do not call this a prosecution b...   \n3                              What is this you say?   \n4  Someone must have indicted you, for you are no...   \n\n                                        sentence_str  \\\n0   What's new, Socrates, to make you leave your ...   \n1  Surely you are not prosecuting anyone before t...   \n2  The Athenians do not call this a prosecution b...   \n3                              What is this you say?   \n4  Someone must have indicted you, for you are no...   \n\n   original_publication_date  corpus_edition_date  sentence_length  \\\n0                       -350                 1997              125   \n1                       -350                 1997               69   \n2                       -350                 1997               74   \n3                       -350                 1997               21   \n4                       -350                 1997              101   \n\n                                    sentence_lowered  \\\n0   what's new, socrates, to make you leave your ...   \n1  surely you are not prosecuting anyone before t...   \n2  the athenians do not call this a prosecution b...   \n3                              what is this you say?   \n4  someone must have indicted you, for you are no...   \n\n                                       tokenized_txt  \\\n0  ['what', 'new', 'socrates', 'to', 'make', 'you...   \n1  ['surely', 'you', 'are', 'not', 'prosecuting',...   \n2  ['the', 'athenians', 'do', 'not', 'call', 'thi...   \n3               ['what', 'is', 'this', 'you', 'say']   \n4  ['someone', 'must', 'have', 'indicted', 'you',...   \n\n                                      lemmatized_str  NumOfWords  \n0     what be new , Socrates , to make -PRON- lea...          24  \n1   surely -PRON- be not prosecute anyone before ...          13  \n2   the Athenians do not call this a prosecution ...          12  \n3                          what be this -PRON- say ?           5  \n4   someone must have indict -PRON- , for -PRON- ...          19  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>title</th>\n      <th>author</th>\n      <th>school</th>\n      <th>sentence_spacy</th>\n      <th>sentence_str</th>\n      <th>original_publication_date</th>\n      <th>corpus_edition_date</th>\n      <th>sentence_length</th>\n      <th>sentence_lowered</th>\n      <th>tokenized_txt</th>\n      <th>lemmatized_str</th>\n      <th>NumOfWords</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Plato - Complete Works</td>\n      <td>Plato</td>\n      <td>plato</td>\n      <td>What's new, Socrates, to make you leave your ...</td>\n      <td>What's new, Socrates, to make you leave your ...</td>\n      <td>-350</td>\n      <td>1997</td>\n      <td>125</td>\n      <td>what's new, socrates, to make you leave your ...</td>\n      <td>['what', 'new', 'socrates', 'to', 'make', 'you...</td>\n      <td>what be new , Socrates , to make -PRON- lea...</td>\n      <td>24</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Plato - Complete Works</td>\n      <td>Plato</td>\n      <td>plato</td>\n      <td>Surely you are not prosecuting anyone before t...</td>\n      <td>Surely you are not prosecuting anyone before t...</td>\n      <td>-350</td>\n      <td>1997</td>\n      <td>69</td>\n      <td>surely you are not prosecuting anyone before t...</td>\n      <td>['surely', 'you', 'are', 'not', 'prosecuting',...</td>\n      <td>surely -PRON- be not prosecute anyone before ...</td>\n      <td>13</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Plato - Complete Works</td>\n      <td>Plato</td>\n      <td>plato</td>\n      <td>The Athenians do not call this a prosecution b...</td>\n      <td>The Athenians do not call this a prosecution b...</td>\n      <td>-350</td>\n      <td>1997</td>\n      <td>74</td>\n      <td>the athenians do not call this a prosecution b...</td>\n      <td>['the', 'athenians', 'do', 'not', 'call', 'thi...</td>\n      <td>the Athenians do not call this a prosecution ...</td>\n      <td>12</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Plato - Complete Works</td>\n      <td>Plato</td>\n      <td>plato</td>\n      <td>What is this you say?</td>\n      <td>What is this you say?</td>\n      <td>-350</td>\n      <td>1997</td>\n      <td>21</td>\n      <td>what is this you say?</td>\n      <td>['what', 'is', 'this', 'you', 'say']</td>\n      <td>what be this -PRON- say ?</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Plato - Complete Works</td>\n      <td>Plato</td>\n      <td>plato</td>\n      <td>Someone must have indicted you, for you are no...</td>\n      <td>Someone must have indicted you, for you are no...</td>\n      <td>-350</td>\n      <td>1997</td>\n      <td>101</td>\n      <td>someone must have indicted you, for you are no...</td>\n      <td>['someone', 'must', 'have', 'indicted', 'you',...</td>\n      <td>someone must have indict -PRON- , for -PRON- ...</td>\n      <td>19</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DF = pd.read_csv(\"philosophy_data.csv\")\n",
    "\n",
    "DF[\"NumOfWords\"]=DF[\"sentence_str\"].apply(lambda x: len(x.split(\" \")))\n",
    "DF.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l3dwcc3cD_pB"
   },
   "source": [
    "Extract the tokenized_txt DF[\"tokenized_txt\"] sentences and append them into a python list."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "6Y41arE5DDMQ",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1633372474347,
     "user_tz": -120,
     "elapsed": 18,
     "user": {
      "displayName": "adam-nord@hotmail.com",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "12454353131717006596"
     }
    }
   },
   "source": [
    "def collect_sentences_from_tokenized_txt(sentences, tokenized_txt):\n",
    "  for i, sentence in enumerate(tokenized_txt):\n",
    "    sentences.append(sentence)\n",
    "  #remove the extra \"\" that were automatically added when appending?\n",
    "  return sentences"
   ],
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vruYssI2Acx6",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1633372474348,
     "user_tz": -120,
     "elapsed": 17,
     "user": {
      "displayName": "adam-nord@hotmail.com",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "12454353131717006596"
     }
    },
    "outputId": "b86cf984-dd78-46de-8576-89d93026c30b"
   },
   "source": [
    "sentences = []\n",
    "collect_sentences_from_tokenized_txt(sentences, DF[\"tokenized_txt\"])\n",
    "sentences[:5]"
   ],
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "[\"['what', 'new', 'socrates', 'to', 'make', 'you', 'leave', 'your', 'usual', 'haunts', 'in', 'the', 'lyceum', 'and', 'spend', 'your', 'time', 'here', 'by', 'the', 'king', 'archon', 'court']\",\n \"['surely', 'you', 'are', 'not', 'prosecuting', 'anyone', 'before', 'the', 'king', 'archon', 'as', 'am']\",\n \"['the', 'athenians', 'do', 'not', 'call', 'this', 'prosecution', 'but', 'an', 'indictment', 'euthyphro']\",\n \"['what', 'is', 'this', 'you', 'say']\",\n \"['someone', 'must', 'have', 'indicted', 'you', 'for', 'you', 'are', 'not', 'going', 'to', 'tell', 'me', 'that', 'you', 'have', 'indicted', 'someone', 'else']\"]"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q9BKM6lsFaq4"
   },
   "source": [
    "Apply and train our own Word2Vec to sentences (Doc2Vec also exists in gensim.models)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "r2I7iVzBElA0",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1633372474349,
     "user_tz": -120,
     "elapsed": 13,
     "user": {
      "displayName": "adam-nord@hotmail.com",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "12454353131717006596"
     }
    }
   },
   "source": [
    "#model = Word2Vec(sentences = sentences, min_count = 1)"
   ],
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3BD89RNMxxEC"
   },
   "source": [
    "Apply the already trained Word2Vec model from Google News dataset that contains about 100 billion words.\n",
    "There's possibility to train our own model on our own data but the results might be worse."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "ijW_CZi3hEAw",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "d1381fc3-db68-407a-acee-185622ea0f5c"
   },
   "source": [
    "\n",
    "for index, word in enumerate(w2v.index_to_key):\n",
    "  if index == 10:\n",
    "    break\n",
    "  print(\"word #{}/{} is {}\".format(index, len(w2v.index_to_key), word))\n",
    "\n",
    "pairs = [\n",
    "    ('car', 'minivan'),   # a minivan is a kind of car\n",
    "    ('car', 'bicycle'),   # still a wheeled vehicle\n",
    "    ('car', 'airplane'),  # ok, no wheels, but still a vehicle\n",
    "    ('car', 'cereal'),    # ... and so on\n",
    "    ('car', 'communism'),\n",
    "]\n",
    "for w1, w2 in pairs:\n",
    "    print('%r\\t%r\\t%.2f' % (w1, w2, w2v.similarity(w1, w2)))\n",
    "\n",
    "print(w2v.most_similar(positive=['car', 'minivan'], topn=5))\n",
    "print(w2v.doesnt_match(['fire', 'water', 'land', 'sea', 'air', 'car']))"
   ],
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word #0/3000000 is </s>\n",
      "word #1/3000000 is in\n",
      "word #2/3000000 is for\n",
      "word #3/3000000 is that\n",
      "word #4/3000000 is is\n",
      "word #5/3000000 is on\n",
      "word #6/3000000 is ##\n",
      "word #7/3000000 is The\n",
      "word #8/3000000 is with\n",
      "word #9/3000000 is said\n",
      "'car'\t'minivan'\t0.69\n",
      "'car'\t'bicycle'\t0.54\n",
      "'car'\t'airplane'\t0.42\n",
      "'car'\t'cereal'\t0.14\n",
      "'car'\t'communism'\t0.06\n",
      "[('SUV', 0.8532192707061768), ('vehicle', 0.8175783753395081), ('pickup_truck', 0.7763688564300537), ('Jeep', 0.7567334175109863), ('Ford_Explorer', 0.7565720081329346)]\n",
      "car\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p96w1y5Jyy-s",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "This function summarizes each vectorized word in a sentence and divides the sum with the amount of words in the sentence.\n",
    "Doing this will allow us to be able to get whole sentences vectorized values instead of individual words."
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "def sentence_vectorizer(sentence, model):\n",
    "    words = []\n",
    "    num_words = 0\n",
    "    for w in sentence:\n",
    "        try:\n",
    "            if num_words == 0:\n",
    "                words = model[w]\n",
    "            else:\n",
    "                words = np.add(words, model[w])\n",
    "        except:\n",
    "            pass\n",
    "        num_words += 1\n",
    "    return np.asarray(words) / num_words"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 9,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Use the above function with our model (in this case w2v) sentences."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([], dtype=float64), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64)]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X = []\n",
    "for sentence in sentences:\n",
    "    X.append(sentence_vectorizer(sentence, w2v))\n",
    "\n",
    "print(X[:5])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ]
}